
# 简介
- 模型选择之后，超参的确定，模型拟合的程度，都需要模型调优使得模型以更加适合所训练的任务。

# 调优方向[^1]
[^1]:[连接](https://blog.csdn.net/weixin_37352167/article/details/84749036)

- 模型调优，首先应解决欠拟合问题，其次再解决过拟合问题。否则即便是过拟合控制得很好（训练精度与测试精度非常接近），但拟合程度却依然很低，达不到目的。
- 更主要的，是从数据的特征入手，好的特征工程决定预测结果的上限。


## 参数调整
- 主要调整模型中的超参数，例如学习速率等。可以使用 网格搜索 方法，或者修改模型结构。

## 效果优化

### 过拟合
- 减小正则项的系数
- 找更多的特征
- 寻找更多的数据
- 换更好的模型

### 欠拟合
- 寻找更多的数据
- 增大正则项的强度
- 减小模型结构的复杂度
- 减少特征个数（不推荐）

## 权重分析
- 对权重绝对值高/低的特征做更精细工作，例如删除权重非常低得特征，保留权重高的特征；或可以将权重高得特征进行粒度细化，发掘其隐藏的特征。

## Bad-Case分析
- 关注错误样本的相关信息：
  - 哪些样本分错了
  - 哪些特征促使模型做出此判断（权值高）
  - 这些 bad-case 存在那些共性
  - 是否有可以继续挖掘的特性
  - 哪些样本预测结果与真实结果差距非常大，以及为什么。



# 调优方法
## 交叉验证[^2]
[^2]:[连接](https://www.cnblogs.com/zhangfengxian/p/10561147.html)

**目的**
- 为了让被评估的模型更加准确可信

**过程**
- 将拿到的数据，分为训练和验证集。以下图为例：将数据分成5份，其中一份作为验证集。然后经过次(组)的测试，每次都更换不同的验证集。即得到5组模型的结果，取平均值作为最终结果。又称5折交叉验证。


## 网格搜索

**目的**
- 超参数搜索

**过程**
- 通常情况下，有很多参数是需要手动指定的（如k-近邻算法中的K值），这种叫超参数。但是手动过程繁杂，所以需要对模型预设几种超参数组合。每组超参数都采用交叉验证来进行评估。最后选出最优参数组合建立模型。


## 模型压缩[^3]
[^3]:[连接](https://www.cnblogs.com/qccz123456/p/12322127.html)

- 深度学习模型优化的方法

- quantization：模型权重量化
- sparsification：模型权重稀疏
- channel pruning：模型通道剪枝
- Distilling：模型蒸馏

## 优化推理引擎

- Intel 的 OpenVINO
- NVIDA 的 tensorRT
- ARM 的 Tengine：https://github.com/OAID/Tengine
- Tencent 针对移动端应用推出 NCNN
- TVM
- XLA 方案？


## 正则化项
- L1正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择
- L2正则化可以防止模型过拟合（overfitting）；一定程度上，L1也可以防止过拟合

## Cost Functions
- 线性回归的均方误差、逻辑回归（即分类问题）的交叉熵


## 卷积层的计算优化
- [Winograd，GEMM算法](https://blog.csdn.net/qq_32998593/article/details/86177151)
- 卷积层的计算优化[im2col](https://blog.csdn.net/dwyane12138/article/details/78449898)
- 卷积层的计算优化[Winograd](https://www.cnblogs.com/shine-lee/p/10906535.html)


